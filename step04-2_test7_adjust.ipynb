{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attached-coach",
   "metadata": {},
   "source": [
    "## Libraries and versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-watershed",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affiliated-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_version = !Python -V #version 3.7.9\n",
    "import pandas as pd #version 1.2.3\n",
    "import numpy as np #version 1.19.2\n",
    "\n",
    "\n",
    "#for machine learning models\n",
    "#pre processing\n",
    "from category_encoders import OneHotEncoder, __version__ as ce_version #version 2.2.2\n",
    "\n",
    "#split data in train and test\n",
    "#version\n",
    "from sklearn import __version__ as sk_version #version 0.24.1\n",
    "\n",
    "#pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#classificators\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-fiction",
   "metadata": {},
   "source": [
    "### Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-motor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.9\n",
      "Pandas version: 1.2.3\n",
      "Numpy version: 1.19.2\n",
      "Category Encoders version: 2.2.2\n",
      "Sklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "print(f'{python_version[0]}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Category Encoders version: {ce_version}')\n",
    "print(f'Sklearn version: {sk_version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-dinner",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crucial-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-picking",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norman-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_cleaning_model7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mature-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>age_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "      <td>18-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "      <td>36-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "      <td>66-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "      <td>66-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "      <td>36-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              1.0   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              1.0   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation age_categories  \n",
       "0            Low          4.0  Cat_4            D          18-25  \n",
       "1        Average          3.0  Cat_4            A          36-40  \n",
       "2            Low          1.0  Cat_6            B          66-70  \n",
       "3           High          2.0  Cat_6            B          66-70  \n",
       "4           High          6.0  Cat_6            A          36-40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-swaziland",
   "metadata": {},
   "source": [
    "## make model better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-outside",
   "metadata": {},
   "source": [
    "OPTIONS\n",
    "\n",
    "- change categories\n",
    "- change dependent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-processor",
   "metadata": {},
   "source": [
    "OBSERVATIONS\n",
    "\n",
    "- model6 has all changes in dataset was maded, so other analysis only will be made if model7 needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-preview",
   "metadata": {},
   "source": [
    "# Dataset transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-newsletter",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-vector",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoder\n",
    "encoder = OneHotEncoder(cols=['Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1'],\n",
    "                       use_cat_names=True)\n",
    "dataset_onehorencoder = encoder.fit_transform(dataset)\n",
    "\n",
    "#map column Segmentation and transform for numeric variables\n",
    "map_segmentation = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "dataset_onehorencoder['Segmentation'] = dataset_onehorencoder['Segmentation'].map(map_segmentation)\n",
    "\n",
    "#drop non used columns ID, Gender and Family_Size\n",
    "dataset_onehorencoder.drop(columns=['ID','Gender', 'Family_Size', 'age_categories'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-bottom",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-california",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suitable-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of all variables, except Segmentation\n",
    "X_onehotencoder = dataset_onehorencoder.loc[:, dataset_onehorencoder.columns != 'Segmentation']\n",
    "y_onehotencoder = dataset_onehorencoder['Segmentation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-virgin",
   "metadata": {},
   "source": [
    "## Test 7 - Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "julian-expression",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY FOR 10 ITERATIONS\n",
      "Max = 0.5402\n",
      "Mean = 0.5229\n",
      "Min = 0.5089\n",
      "Std = 0.0109\n",
      "DecisionTreeClassifier(max_depth=5, min_samples_leaf=30)\n"
     ]
    }
   ],
   "source": [
    "#first - split train and test data\n",
    "accuracy_list = []\n",
    "iterations = 10\n",
    "for iter in range(0, iterations):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_onehotencoder, y_onehotencoder, train_size=0.7,\n",
    "                                                        stratify=y_onehotencoder)\n",
    "\n",
    "    #third - macinhe learning apply\n",
    "    model7 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=30)\n",
    "    model7.fit(X_train, y_train)\n",
    "    y_predict = model7.predict(X_test)\n",
    "\n",
    "    #fourth - test accuray\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "max_accuracy = np.asarray(accuracy_list).max()\n",
    "mean_accuracy = np.asarray(accuracy_list).mean()\n",
    "min_accuracy = np.asarray(accuracy_list).min()\n",
    "std_accuracy = np.asarray(accuracy_list).std()\n",
    "print(f'ACCURACY FOR {iterations} ITERATIONS')\n",
    "print(f'Max = {max_accuracy:.4f}\\nMean = {mean_accuracy:.4f}\\nMin = {min_accuracy:.4f}\\nStd = {std_accuracy:.4f}')\n",
    "print(model7.set_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moved-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DataFrame with errors\n",
    "dict_compare = {'Real':y_test.values, 'Predict':y_predict}\n",
    "dataset_error = pd.DataFrame(dict_compare, index=y_test.index)\n",
    "dataset_error['Error'] = dataset_error['Real'] !=dataset_error['Predict']\n",
    "dataset_error['Cat_Real'] = dataset_error['Real'].map({0:'A', 1:'B', 2:'C', 3:'D'})\n",
    "dataset_error['Cat_Predict'] = dataset_error['Predict'].map({0:'A', 1:'B', 2:'C', 3:'D'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "otherwise-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Error for each Segmentation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Error</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.508929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.295880</td>\n",
       "      <td>0.704120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.581722</td>\n",
       "      <td>0.418278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.735110</td>\n",
       "      <td>0.264890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Error        False     True \n",
       "Cat_Real                    \n",
       "A         0.491071  0.508929\n",
       "B         0.295880  0.704120\n",
       "C         0.581722  0.418278\n",
       "D         0.735110  0.264890"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percent of Error for each Segmentation')\n",
    "pd.crosstab(index=dataset_error['Cat_Real'], columns=dataset_error['Error'], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "atomic-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Artist</th>\n",
       "      <td>0.165142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Low</th>\n",
       "      <td>0.152281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <td>0.035741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <td>0.030443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <td>0.021611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Marketing</th>\n",
       "      <td>0.019851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_Experience</th>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Average</th>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_No</th>\n",
       "      <td>0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_No</th>\n",
       "      <td>0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Executive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_High</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Importance\n",
       "Age                         0.554100\n",
       "Profession_Artist           0.165142\n",
       "Spending_Score_Low          0.152281\n",
       "Profession_Healthcare       0.035741\n",
       "Graduated_Yes               0.030443\n",
       "Profession_Entertainment    0.021611\n",
       "Profession_Marketing        0.019851\n",
       "Work_Experience             0.006227\n",
       "Spending_Score_Average      0.005195\n",
       "Graduated_No                0.005058\n",
       "Ever_Married_No             0.004115\n",
       "Profession_Doctor           0.000236\n",
       "Profession_Homemaker        0.000000\n",
       "Profession_Executive        0.000000\n",
       "Ever_Married_Yes            0.000000\n",
       "Profession_Lawyer           0.000000\n",
       "Profession_Engineer         0.000000\n",
       "Spending_Score_High         0.000000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model7.feature_importances_\n",
    "pd.DataFrame(data={'Importance':importance}, index=X_onehotencoder.columns).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-calculation",
   "metadata": {},
   "source": [
    "# Tests for model 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-iceland",
   "metadata": {},
   "source": [
    "## Encoders - exclude variable Var_1 and change params (class_weight, entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-inspection",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "czech-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoder\n",
    "encoder = OneHotEncoder(cols=['Ever_Married', 'Graduated', 'Profession', 'Spending_Score'],\n",
    "                       use_cat_names=True)\n",
    "dataset_onehorencoder = encoder.fit_transform(dataset)\n",
    "\n",
    "#map column Segmentation and transform for numeric variables\n",
    "map_segmentation = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "dataset_onehorencoder['Segmentation'] = dataset_onehorencoder['Segmentation'].map(map_segmentation)\n",
    "\n",
    "#drop non used columns ID, Gender and Family_Size\n",
    "dataset_onehorencoder.drop(columns=['ID','Gender', 'Family_Size', 'age_categories', 'Var_1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-irish",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-prescription",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "signed-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of all variables, except Segmentation\n",
    "X_onehotencoder = dataset_onehorencoder.loc[:, dataset_onehorencoder.columns != 'Segmentation']\n",
    "y_onehotencoder = dataset_onehorencoder['Segmentation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-ratio",
   "metadata": {},
   "source": [
    "### model7_1 - exclude Var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "premier-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for model7_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.277350\n",
       "2    0.247229\n",
       "0    0.243448\n",
       "1    0.231973\n",
       "Name: Segmentation, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Weight for model7_1')\n",
    "y_onehotencoder.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "thick-receiver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY FOR 50 ITERATIONS\n",
      "Max = 0.5419\n",
      "Mean = 0.5232\n",
      "Min = 0.5093\n",
      "Std = 0.0082\n",
      "DecisionTreeClassifier(class_weight={0: 0.24, 1: 0.23, 2: 0.24, 3: 0.27},\n",
      "                       criterion='entropy', max_depth=5, min_samples_leaf=30)\n"
     ]
    }
   ],
   "source": [
    "#first - split train and test data\n",
    "accuracy_list = []\n",
    "iterations = 50\n",
    "for iter in range(0, iterations):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_onehotencoder, y_onehotencoder, train_size=0.7,\n",
    "                                                        stratify=y_onehotencoder)\n",
    "\n",
    "    #third - macinhe learning apply\n",
    "    model7_1 = DecisionTreeClassifier(max_depth=5,\n",
    "                                      min_samples_leaf=30,\n",
    "                                      criterion='entropy',\n",
    "                                      class_weight={0:0.24, 1:0.23, 2:0.24, 3:0.27})\n",
    "    model7_1.fit(X_train, y_train)\n",
    "    y_predict = model7_1.predict(X_test)\n",
    "\n",
    "    #fourth - test accuray\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "max_accuracy = np.asarray(accuracy_list).max()\n",
    "mean_accuracy = np.asarray(accuracy_list).mean()\n",
    "min_accuracy = np.asarray(accuracy_list).min()\n",
    "std_accuracy = np.asarray(accuracy_list).std()\n",
    "print(f'ACCURACY FOR {iterations} ITERATIONS')\n",
    "print(f'Max = {max_accuracy:.4f}\\nMean = {mean_accuracy:.4f}\\nMin = {min_accuracy:.4f}\\nStd = {std_accuracy:.4f}')\n",
    "print(model7_1.set_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "monetary-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DataFrame with errors\n",
    "dict_compare = {'Real':y_test.values, 'Predict':y_predict}\n",
    "dataset_error = pd.DataFrame(dict_compare, index=y_test.index)\n",
    "dataset_error['Error'] = dataset_error['Real'] !=dataset_error['Predict']\n",
    "dataset_error['Cat_Real'] = dataset_error['Real'].map({0:'A', 1:'B', 2:'C', 3:'D'})\n",
    "dataset_error['Cat_Predict'] = dataset_error['Predict'].map({0:'A', 1:'B', 2:'C', 3:'D'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "other-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Error for each Segmentation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Error</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.533929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.340824</td>\n",
       "      <td>0.659176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.558875</td>\n",
       "      <td>0.441125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Error        False     True \n",
       "Cat_Real                    \n",
       "A         0.466071  0.533929\n",
       "B         0.340824  0.659176\n",
       "C         0.558875  0.441125\n",
       "D         0.681818  0.318182"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percent of Error for each Segmentation')\n",
    "pd.crosstab(index=dataset_error['Cat_Real'], columns=dataset_error['Error'], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "apparent-christianity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.508530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Artist</th>\n",
       "      <td>0.180997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Low</th>\n",
       "      <td>0.152421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <td>0.064199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_No</th>\n",
       "      <td>0.033653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <td>0.012539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_Experience</th>\n",
       "      <td>0.010888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <td>0.010545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Marketing</th>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <td>0.007539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_High</th>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Average</th>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Executive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_No</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Importance\n",
       "Age                         0.508530\n",
       "Profession_Artist           0.180997\n",
       "Spending_Score_Low          0.152421\n",
       "Profession_Healthcare       0.064199\n",
       "Graduated_No                0.033653\n",
       "Profession_Entertainment    0.012539\n",
       "Work_Experience             0.010888\n",
       "Ever_Married_Yes            0.010545\n",
       "Profession_Marketing        0.009000\n",
       "Graduated_Yes               0.007539\n",
       "Spending_Score_High         0.005142\n",
       "Spending_Score_Average      0.004548\n",
       "Profession_Doctor           0.000000\n",
       "Profession_Homemaker        0.000000\n",
       "Profession_Executive        0.000000\n",
       "Profession_Lawyer           0.000000\n",
       "Profession_Engineer         0.000000\n",
       "Ever_Married_No             0.000000"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model7_1.feature_importances_\n",
    "pd.DataFrame(data={'Importance':importance}, index=X_onehotencoder.columns).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-female",
   "metadata": {},
   "source": [
    "- Age is more than 50% factor of decision for model7 e model7_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-palmer",
   "metadata": {},
   "source": [
    "### Model7_2 - add age_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "union-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoder\n",
    "encoder = OneHotEncoder(cols=['Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'age_categories'],\n",
    "                       use_cat_names=True)\n",
    "dataset_onehorencoder_new = encoder.fit_transform(dataset)\n",
    "\n",
    "#map column Segmentation and transform for numeric variables\n",
    "map_segmentation = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "dataset_onehorencoder_new['Segmentation'] = dataset_onehorencoder_new['Segmentation'].map(map_segmentation)\n",
    "\n",
    "#drop non used columns ID, Gender and Family_Size\n",
    "dataset_onehorencoder_new.drop(columns=['ID','Gender', 'Family_Size', 'Var_1', 'Age' ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-jacksonville",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-handling",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "common-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of all variables, except Segmentation\n",
    "X_onehotencoder_new = dataset_onehorencoder_new.loc[:, dataset_onehorencoder_new.columns != 'Segmentation']\n",
    "y_onehotencoder_new = dataset_onehorencoder_new['Segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "tribal-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY FOR 20 ITERATIONS\n",
      "Max = 0.5054\n",
      "Mean = 0.4913\n",
      "Min = 0.4781\n",
      "Std = 0.0074\n",
      "DecisionTreeClassifier(class_weight={0: 0.24, 1: 0.23, 2: 0.24, 3: 0.27},\n",
      "                       criterion='entropy', max_depth=5, min_samples_leaf=30)\n"
     ]
    }
   ],
   "source": [
    "#first - split train and test data\n",
    "accuracy_list = []\n",
    "iterations = 20\n",
    "for iter in range(0, iterations):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_onehotencoder_new, y_onehotencoder_new, train_size=0.7,\n",
    "                                                        stratify=y_onehotencoder_new)\n",
    "\n",
    "    #third - macinhe learning apply\n",
    "    model7_2 = DecisionTreeClassifier(max_depth=5,\n",
    "                                      min_samples_leaf=30,\n",
    "                                      criterion='entropy',\n",
    "                                      class_weight={0:0.24, 1:0.23, 2:0.24, 3:0.27})\n",
    "    model7_2.fit(X_train, y_train)\n",
    "    y_predict = model7_2.predict(X_test)\n",
    "\n",
    "    #fourth - test accuray\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "max_accuracy = np.asarray(accuracy_list).max()\n",
    "mean_accuracy = np.asarray(accuracy_list).mean()\n",
    "min_accuracy = np.asarray(accuracy_list).min()\n",
    "std_accuracy = np.asarray(accuracy_list).std()\n",
    "print(f'ACCURACY FOR {iterations} ITERATIONS')\n",
    "print(f'Max = {max_accuracy:.4f}\\nMean = {mean_accuracy:.4f}\\nMin = {min_accuracy:.4f}\\nStd = {std_accuracy:.4f}')\n",
    "print(model7_2.set_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "reasonable-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DataFrame with errors\n",
    "dict_compare = {'Real':y_test.values, 'Predict':y_predict}\n",
    "dataset_error = pd.DataFrame(dict_compare, index=y_test.index)\n",
    "dataset_error['Error'] = dataset_error['Real'] !=dataset_error['Predict']\n",
    "dataset_error['Cat_Real'] = dataset_error['Real'].map({0:'A', 1:'B', 2:'C', 3:'D'})\n",
    "dataset_error['Cat_Predict'] = dataset_error['Predict'].map({0:'A', 1:'B', 2:'C', 3:'D'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "portuguese-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Error for each Segmentation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Error</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_Real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.352060</td>\n",
       "      <td>0.647940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.411248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Error        False     True \n",
       "Cat_Real                    \n",
       "A         0.312500  0.687500\n",
       "B         0.352060  0.647940\n",
       "C         0.588752  0.411248\n",
       "D         0.689655  0.310345"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percent of Error for each Segmentation')\n",
    "pd.crosstab(index=dataset_error['Cat_Real'], columns=dataset_error['Error'], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "vertical-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Low</th>\n",
       "      <td>0.333505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <td>0.214028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Artist</th>\n",
       "      <td>0.204484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_18-25</th>\n",
       "      <td>0.071944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <td>0.045645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_26-30</th>\n",
       "      <td>0.026607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_31-35</th>\n",
       "      <td>0.022459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_No</th>\n",
       "      <td>0.022068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_No</th>\n",
       "      <td>0.017074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_Experience</th>\n",
       "      <td>0.015282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_56-60</th>\n",
       "      <td>0.010376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Marketing</th>\n",
       "      <td>0.010296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_46-50</th>\n",
       "      <td>0.006234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_75+</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_41-45</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_51-55</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_61-65</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_36-40</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_66-70</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Executive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_High</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_Average</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_categories_71-75</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Importance\n",
       "Spending_Score_Low          0.333505\n",
       "Profession_Healthcare       0.214028\n",
       "Profession_Artist           0.204484\n",
       "age_categories_18-25        0.071944\n",
       "Graduated_Yes               0.045645\n",
       "age_categories_26-30        0.026607\n",
       "age_categories_31-35        0.022459\n",
       "Ever_Married_No             0.022068\n",
       "Graduated_No                0.017074\n",
       "Work_Experience             0.015282\n",
       "age_categories_56-60        0.010376\n",
       "Profession_Marketing        0.010296\n",
       "age_categories_46-50        0.006234\n",
       "Profession_Entertainment    0.000000\n",
       "age_categories_75+          0.000000\n",
       "age_categories_41-45        0.000000\n",
       "age_categories_51-55        0.000000\n",
       "age_categories_61-65        0.000000\n",
       "Profession_Engineer         0.000000\n",
       "age_categories_36-40        0.000000\n",
       "age_categories_66-70        0.000000\n",
       "Profession_Executive        0.000000\n",
       "Profession_Lawyer           0.000000\n",
       "Spending_Score_High         0.000000\n",
       "Spending_Score_Average      0.000000\n",
       "Ever_Married_Yes            0.000000\n",
       "Profession_Homemaker        0.000000\n",
       "Profession_Doctor           0.000000\n",
       "age_categories_71-75        0.000000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model7_2.feature_importances_\n",
    "pd.DataFrame(data={'Importance':importance}, index=X_onehotencoder_new.columns).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-soccer",
   "metadata": {},
   "source": [
    "- seems which divide Age in categories did not increase mean accuracy, but that change maked model understand better segmentations (not too much better)\n",
    "- there is important train the model with other categories in profession variable (create categorie Bussiness = Executive + Marketing, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-ozone",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-estimate",
   "metadata": {},
   "source": [
    "- split variable Age did not work with use onehotencoder, because accuracy is less then 50% and did not solve problem os segmentation\n",
    "- the best model is model7_1, which reach 52% os accuracy, but have some problems with distinction of each segmentation and the importance of variable Age with almost 50%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
